{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyBg-0SMAVle"
      },
      "source": [
        "# Code of Group 12, TM10007: Project 4 - ECG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSxM5s8WAbif"
      },
      "source": [
        "##Importeren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frcCg7BaAact"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import subprocess\n",
        "import shutil\n",
        "import stat\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from os import path\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score, make_scorer, fbeta_score, RocCurveDisplay\n",
        "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, learning_curve, train_test_split, cross_val_predict, GridSearchCV, cross_validate, ShuffleSplit\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import kstest\n",
        "\n",
        "## if data.csv is not present download it from github\n",
        "if not os.path.isfile(\"ecg_data.csv\"):\n",
        "    ## clone repo from githun\n",
        "    if not os.path.isdir(\"tm10007_ml\"):\n",
        "        !git clone https://github.com/jveenland/tm10007_ml.git\n",
        "    ## extract zip file\n",
        "    if not os.path.isfile(\"tm10007_ml/ecg/ecg_data.csv\"):\n",
        "        with zipfile.ZipFile('tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('tm10007_ml/ecg')\n",
        "    ## move data file to root folder\n",
        "    shutil.move('tm10007_ml/ecg/ecg_data.csv', 'ecg_data.csv')\n",
        "\n",
        "    ## Delete cloned repo\n",
        "    for root, dirs, files in os.walk(\"./tm10007_ml\"):  \n",
        "        for dir in dirs:\n",
        "            os.chmod(path.join(root, dir), stat.S_IRWXU)\n",
        "        for file in files:\n",
        "            os.chmod(path.join(root, file), stat.S_IRWXU)\n",
        "    shutil.rmtree('./tm10007_ml')\n",
        "\n",
        "data = pd.read_csv('ecg_data.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4SRgyIYGVG2"
      },
      "source": [
        "## Inspect imported data and clean missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3__QWcg2GVw6"
      },
      "source": [
        "### Plot number of missing data per features and per patient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rS42QDaGmlW"
      },
      "outputs": [],
      "source": [
        "# exclude label column\n",
        "values_features = data.drop(['label'], axis=1)\n",
        "\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_features == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_features == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVa0bSt-KRGo"
      },
      "source": [
        "### Create function 'clean_outlier'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab7OR11EKTbG"
      },
      "outputs": [],
      "source": [
        "def clean_outlier(dataframe):\n",
        "  new_dfs = []\n",
        "  for i in range(9000):\n",
        "        data=dataframe[dataframe.columns[i]]\n",
        "        Q1 = np.percentile(data, 25)\n",
        "        Q3 = np.percentile(data, 75)\n",
        "        IQD = Q3 - Q1\n",
        "        Upper_outlier_boundary = Q3 + (1.5 * IQD)\n",
        "        Lower_outlier_boundary = Q1 - (1.5 * IQD)\n",
        "        clipped_col = pd.DataFrame({dataframe.columns[i]: dataframe[dataframe.columns[i]].clip(Lower_outlier_boundary, Upper_outlier_boundary)})\n",
        "        new_dfs.append(clipped_col)\n",
        "  clean_outlier_data = pd.concat(new_dfs, axis=1)\n",
        "  clean_outlier_data= pd.concat([clean_outlier_data,dataframe.iloc[:,-1]], axis=1)\n",
        "  return clean_outlier_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtvZdr00GsZx"
      },
      "source": [
        "### Delete rows with missing data & clean data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytm3h8iyGn3E"
      },
      "outputs": [],
      "source": [
        "values_data = data.drop(['label'], axis=1)\n",
        "mask = (values_data != 0).all(axis=1)\n",
        "clean_data_raw=data[mask]\n",
        "dirty_data=data[~mask]\n",
        "clean_data = clean_outlier(clean_data_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FljpyvhSG4Eu"
      },
      "source": [
        "### Plot number of missing data per features and per patient after data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpxxIklGG4j7"
      },
      "outputs": [],
      "source": [
        "# exclude label column\n",
        "values_clean_data = clean_data.drop(['label'], axis=1)\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_clean_data == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_clean_data == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6WahJJHAnY"
      },
      "source": [
        "### Check distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUgsHsR9HCcW"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import kstest\n",
        "# Statistical tests for normality\n",
        "ks_counter_normal = 0\n",
        "ks_counter_not_normal = 0\n",
        "p_values = []\n",
        "\n",
        "for col in values_clean_data.columns:\n",
        "    # Kolmogorov-Smirnov test\n",
        "    p_value_ks = kstest(values_clean_data[col], 'norm')[1]\n",
        "    p_values.append(p_value_ks)\n",
        "    if p_value_ks > 0.05:\n",
        "        print(f\"{col} is normally distributed (Kolmogorov-Smirnov test p-value = {p_value_ks})\")\n",
        "        ks_counter_normal += 1\n",
        "    else:\n",
        "      ks_counter_not_normal += 1\n",
        "\n",
        "print(f\"The Kolmogorov-Smirnov test gave {ks_counter_normal} normally distributed frequencies & {ks_counter_not_normal} not normally distributed frequencies\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71meoJjmHW16"
      },
      "source": [
        "## For loop cross-val train-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlzTp0WWHbCZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# KNN scores\n",
        "mean_accuracy_scores_knn = []\n",
        "mean_precision_scores_knn  = []\n",
        "mean_recall_scores_knn  = []\n",
        "mean_f1_scores_knn  = []\n",
        "mean_fbeta_scores_knn  = [] \n",
        "\n",
        "# SVM scores\n",
        "mean_accuracy_scores_svm = []\n",
        "mean_precision_scores_svm  = []\n",
        "mean_recall_scores_svm  = []\n",
        "mean_f1_scores_svm  = []\n",
        "mean_fbeta_scores_svm  = [] \n",
        "\n",
        "# SVM Poly scores\n",
        "mean_accuracy_scores_svmpoly = []\n",
        "mean_precision_scores_svmpoly  = []\n",
        "mean_recall_scores_svmpoly  = []\n",
        "mean_f1_scores_svmpoly  = []\n",
        "mean_fbeta_scores_svmpoly  = [] \n",
        "\n",
        "# Desicion tree scores\n",
        "mean_accuracy_scores_dt = []\n",
        "mean_precision_scores_dt  = []\n",
        "mean_recall_scores_dt  = []\n",
        "mean_f1_scores_dt  = []\n",
        "mean_fbeta_scores_dt  = [] \n",
        "\n",
        "# Random forest scores\n",
        "mean_accuracy_scores_rf = []\n",
        "mean_precision_scores_rf  = []\n",
        "mean_recall_scores_rf  = []\n",
        "mean_f1_scores_rf  = []\n",
        "mean_fbeta_scores_rf = [] \n",
        "\n",
        "# Linear (linear regression) classifier\n",
        "mean_accuracy_scores_lr = []\n",
        "mean_precision_scores_lr  = []\n",
        "mean_recall_scores_lr  = []\n",
        "mean_f1_scores_lr  = []\n",
        "mean_fbeta_scores_lr  = [] \n",
        "\n",
        "# combination classifier\n",
        "mean_accuracy_scores_combi = []\n",
        "mean_precision_scores_combi  = []\n",
        "mean_recall_scores_combi  = []\n",
        "mean_f1_scores_combi  = []\n",
        "mean_fbeta_scores_combi  = [] \n",
        "mean_train_scores = []\n",
        "std_train_scores = []\n",
        "mean_test_scores = []\n",
        "std_test_scores = []\n",
        "\n",
        "# KNN scores\n",
        "knn_accuracy_test = []\n",
        "knn_precision_test = []\n",
        "knn_recall_test = []\n",
        "knn_f1_test = []\n",
        "knn_fbeta_test = []\n",
        "\n",
        "# SVM scores\n",
        "svm_accuracy_test = []\n",
        "svm_precision_test = []\n",
        "svm_recall_test = []\n",
        "svm_f1_test = []\n",
        "svm_fbeta_test = []\n",
        "\n",
        "# SVM Poly scores\n",
        "svmpoly_accuracy_test = []\n",
        "svmpoly_precision_test = []\n",
        "svmpoly_recall_test = []\n",
        "svmpoly_f1_test = []\n",
        "svmpoly_fbeta_test = []\n",
        "\n",
        "# Desicion tree scores\n",
        "dt_accuracy_test = []\n",
        "dt_precision_test = []\n",
        "dt_recall_test = []\n",
        "dt_f1_test = []\n",
        "dt_fbeta_test = []\n",
        "\n",
        "# Random forest scores\n",
        "rf_accuracy_test = []\n",
        "rf_precision_test = []\n",
        "rf_recall_test = []\n",
        "rf_f1_test = []\n",
        "rf_fbeta_test = []\n",
        "\n",
        "# Linear (linear regression) classifier\n",
        "lr_accuracy_test = []\n",
        "lr_precision_test = []\n",
        "lr_recall_test = []\n",
        "lr_f1_test = []\n",
        "lr_fbeta_test = []\n",
        "\n",
        "# combination classifier\n",
        "combi_accuracy_test = []\n",
        "combi_precision_test = []\n",
        "combi_recall_test = []\n",
        "combi_f1_test = []\n",
        "combi_fbeta_test = []\n",
        "\n",
        "best_hyper_param_knn = []\n",
        "best_hyper_param_svm = []\n",
        "best_hyper_param_svmpoly = []\n",
        "best_hyper_param_dt = []\n",
        "best_hyper_param_rf = []\n",
        "best_hyper_param_lr = []\n",
        "\n",
        "# Learning curve - combination classifier\n",
        "\n",
        "\n",
        "# Stratified to keep the balance of the classes the same in the splits\n",
        "skf = StratifiedKFold(n_splits=5, random_state=30, shuffle=True)\n",
        "\n",
        "x_forloop = clean_data.iloc[:, :-1].values\n",
        "y_forloop = clean_data.iloc[:, -1].values\n",
        "\n",
        "\n",
        "for fold, (train_indices, test_indices) in enumerate(skf.split(x_forloop, y_forloop)):\n",
        "    train_set = clean_data.iloc[train_indices]\n",
        "    test_set = clean_data.iloc[test_indices]\n",
        "\n",
        "################################### downsampling ###############################\n",
        "    # Separate abnormal and normal data in the training set\n",
        "    ECG_TRAIN_ABNORMAL = train_set[train_set['label'] == 1]\n",
        "    ECG_TRAIN_NORMAL = train_set[train_set['label'] == 0]\n",
        "\n",
        "    # Downsample the normal data to balance the classes\n",
        "    ECG_TRAIN_DOWNSAMPLED = resample(ECG_TRAIN_NORMAL,\n",
        "                                    replace=False,\n",
        "                                    n_samples=len(ECG_TRAIN_ABNORMAL),\n",
        "                                    random_state=30)\n",
        "    # Combine the downsampled normal data with the abnormal data\n",
        "    train_set_downsampled = pd.concat([ECG_TRAIN_ABNORMAL, ECG_TRAIN_DOWNSAMPLED])\n",
        "\n",
        "    # Shuffle the training set\n",
        "    train_set_shuffled = train_set_downsampled.sample(frac=1, random_state=30)\n",
        "\n",
        "################################### scaling ####################################\n",
        "    # scaling the data between 0 and 1\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    # fit the scaler on the train set\n",
        "    scaler.fit(train_set_shuffled)\n",
        "\n",
        "\n",
        "    # transform both train and test data set with the scaler\n",
        "    train_set_scaled = pd.DataFrame(scaler.transform(train_set_shuffled))\n",
        "    train_set_scaled.columns=data.columns.values\n",
        "    test_set_scaled = pd.DataFrame(scaler.transform(test_set))\n",
        "    test_set_scaled.columns=data.columns.values        \n",
        "\n",
        "################################### PCA ########################################\n",
        "    x_pca_train_init = train_set_scaled.iloc[:, :-1].values\n",
        "    pca = PCA(56)\n",
        "    pca.fit(x_pca_train_init)\n",
        "\n",
        "\n",
        "    X_pca_train = pca.transform(x_pca_train_init)\n",
        "    y_pca_train = train_set_scaled.iloc[:, -1].values\n",
        "\n",
        "    x_pca_test_init = test_set_scaled.iloc[:, :-1].values \n",
        "    X_pca_test = pca.transform(x_pca_test_init)\n",
        "    y_pca_test = test_set_scaled.iloc[:, -1].values  \n",
        "\n",
        "\n",
        "\n",
        "################################### KNN ########################################\n",
        "    knn = KNeighborsClassifier(n_neighbors = 3, weights='uniform')\n",
        "    knn.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(knn, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_knn.append(mean_accuracy_score)\n",
        "    #print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(knn, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_knn.append(mean_precision_score)\n",
        "    #print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(knn, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_knn.append(mean_recall_score)\n",
        "    #print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(knn, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_knn.append(mean_f1_score)\n",
        "    #print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(knn, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_knn.append(mean_fbeta_score)\n",
        "    #print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "    # print(\"\")\n",
        "\n",
        "    \n",
        "    # parameters = {'n_neighbors': [3, 5, 7, 9],'weights': ['uniform', 'distance']}\n",
        "    # grid_search = GridSearchCV(knn, param_grid=parameters, cv=5, scoring=fbeta_scorer)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_knn.append(best_hyper_param)\n",
        "\n",
        "################################### SVM RBF #####################################\n",
        "    svmrbf = SVC(kernel='rbf', gamma=10, C=0.1)\n",
        "    svmrbf.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(svmrbf, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_svm.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(svmrbf, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_svm.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(svmrbf, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_svm.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(svmrbf, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_svm.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(svmrbf, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_svm.append(mean_fbeta_score)\n",
        "\n",
        "    # param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
        "    # grid_search = GridSearchCV(estimator=svmrbf, param_grid=param_grid, cv=skf, scoring=fbeta_scorer)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_svm.append(best_hyper_param)\n",
        "\n",
        "################################### svmpoly #####################################\n",
        "    svmpoly = SVC(kernel='poly', degree=1, gamma='scale', C=10)\n",
        "    svmpoly.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(svmpoly, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_svmpoly.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(svmpoly, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_svmpoly.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(svmpoly, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_svmpoly.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(svmpoly, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_svmpoly.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(svmpoly, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_svmpoly.append(mean_fbeta_score)\n",
        "\n",
        "    # param_grid = {'C': [0.1, 1, 10], 'kernel': ['poly'], 'degree': [1, 2, 3, 4], 'gamma': ['scale', 'auto']}\n",
        "    # grid_search = GridSearchCV(svmpoly, param_grid=param_grid, scoring=fbeta_scorer, cv=5)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_svmpoly.append(best_hyper_param)\n",
        "################################# Decision tree ################################\n",
        "    decision_tree = DecisionTreeClassifier(max_depth= 10, min_samples_leaf=4, min_samples_split=10)\n",
        "    decision_tree.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(decision_tree, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_dt.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(decision_tree, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_dt.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(decision_tree, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_dt.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(decision_tree, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_dt.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(decision_tree, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_dt.append(mean_fbeta_score)\n",
        "\n",
        "    # params = {'max_depth': [None, 5, 10, 15, 20],\n",
        "    #         'min_samples_split': [2, 5, 10, 15],\n",
        "    #         'min_samples_leaf': [1, 2, 4, 8, 16]}\n",
        "\n",
        "    # grid_search = GridSearchCV(decision_tree, param_grid=params, cv=5, scoring=fbeta_scorer)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_dt.append(best_hyper_param)\n",
        "\n",
        "################################# Random forest ################################\n",
        "    random_forest = RandomForestClassifier(max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300)\n",
        "    random_forest.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(random_forest, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_rf.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(random_forest, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_rf.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(random_forest, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_rf.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(random_forest, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_rf.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(random_forest, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_rf.append(mean_fbeta_score)\n",
        "\n",
        "    # params = {'n_estimators': [100, 200, 300],\n",
        "    #         'max_depth': [None, 5, 10],\n",
        "    #         'min_samples_split': [2, 5, 10],\n",
        "    #         'min_samples_leaf': [1, 2, 4]}\n",
        "\n",
        "    # grid_search = GridSearchCV(random_forest, param_grid=params, cv=5, scoring=fbeta_scorer)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_rf.append(best_hyper_param)\n",
        "\n",
        "############################## Linear Regression ###############################\n",
        "    linear = LogisticRegression(C=0.1, penalty='l2', max_iter=1000)\n",
        "    linear.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(linear, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_lr.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(linear, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_lr.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(linear, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_lr.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(linear, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_lr.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(linear, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_lr.append(mean_fbeta_score)\n",
        "\n",
        "    # param_grid = {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "    # grid_search = GridSearchCV(linear, param_grid, cv=5, scoring=fbeta_scorer)\n",
        "    # grid_search.fit(X_pca, y_pca_init)\n",
        "    # best_hyper_param=grid_search.best_params_\n",
        "    # best_hyper_param_lr.append(best_hyper_param)\n",
        "\n",
        "################################# Combination ##################################\n",
        "    # estimators = [('decision tree', decision_tree), ('svmpoly', svmpoly), ('linear', linear)]\n",
        "    estimators = [('svm', svmrbf), ('random forrest', random_forest), ('linear', linear)]\n",
        "    combined = VotingClassifier(estimators, voting='hard')\n",
        "    combined.fit(X_pca_train,y_pca_train)\n",
        "\n",
        "    # Compute the accuracy of the classifier\n",
        "    binary_accuracy = make_scorer(accuracy_score)\n",
        "    accuracy_scores = cross_val_score(combined, X_pca_train, y_pca_train, cv=skf, scoring=binary_accuracy)\n",
        "    mean_accuracy_score = accuracy_scores.mean()\n",
        "    mean_accuracy_scores_combi.append(mean_accuracy_score)\n",
        "\n",
        "    # Compute the precision of the classifier\n",
        "    binary_precision = make_scorer(precision_score, average='binary', zero_division=0)\n",
        "    precision_scores = cross_val_score(combined, X_pca_train, y_pca_train, cv=skf, scoring=binary_precision)\n",
        "    mean_precision_score = precision_scores.mean()\n",
        "    mean_precision_scores_combi.append(mean_precision_score)\n",
        "\n",
        "    # Compute the recall of the classifier\n",
        "    binary_recall = make_scorer(recall_score, average='binary')\n",
        "    recall_scores = cross_val_score(combined, X_pca_train, y_pca_train, cv=skf, scoring=binary_recall)\n",
        "    mean_recall_score = recall_scores.mean()\n",
        "    mean_recall_scores_combi.append(mean_recall_score)\n",
        "\n",
        "    # Compute the F1 score of the classifier\n",
        "    binary_f1 = make_scorer(f1_score, average='binary')\n",
        "    f1_scores = cross_val_score(combined, X_pca_train, y_pca_train, cv=skf, scoring=binary_f1)\n",
        "    mean_f1_score = f1_scores.mean()\n",
        "    mean_f1_scores_combi.append(mean_f1_score)\n",
        "\n",
        "    # Compute the weighted F1 score of the classifier\n",
        "    fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "    fbeta_scores = cross_val_score(combined, X_pca_train, y_pca_train, cv=skf, scoring=fbeta_scorer)\n",
        "    mean_fbeta_score = fbeta_scores.mean()\n",
        "    mean_fbeta_scores_combi.append(mean_fbeta_score)\n",
        "\n",
        "    # Plot the learning curve\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "    combined, X_pca_train, y_pca_train, cv=skf, scoring='f1_weighted', n_jobs=-1)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    mean_train_scores.append(train_scores_mean) \n",
        "    std_train_scores.append(train_scores_std)\n",
        "    mean_test_scores.append(test_scores_mean)\n",
        "    std_test_scores.append(test_scores_std)\n",
        "\n",
        "    ##########################################################################################\n",
        "    ################################### testset validatie ####################################\n",
        "    ################################### KNN ##################################################\n",
        "\n",
        "    y_pred = knn.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    knn_accuracy_test.append(accuracy)\n",
        "    knn_precision_test.append(precision)\n",
        "    knn_recall_test.append(recall)\n",
        "    knn_f1_test.append(f1)\n",
        "    knn_fbeta_test.append(fbeta)\n",
        "\n",
        "\n",
        "################################### SVM RBF #####################################\n",
        "\n",
        "    y_pred = svmrbf.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    svm_accuracy_test.append(accuracy)\n",
        "    svm_precision_test.append(precision)\n",
        "    svm_recall_test.append(recall)\n",
        "    svm_f1_test.append(f1)\n",
        "    svm_fbeta_test.append(fbeta)\n",
        "\n",
        "\n",
        "################################### svmpoly #####################################\n",
        " \n",
        "    y_pred = svmpoly.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    svmpoly_accuracy_test.append(accuracy)\n",
        "    svmpoly_precision_test.append(precision)\n",
        "    svmpoly_recall_test.append(recall)\n",
        "    svmpoly_f1_test.append(f1)\n",
        "    svmpoly_fbeta_test.append(fbeta)\n",
        "\n",
        "\n",
        "################################# Decision tree ################################\n",
        " \n",
        "    y_pred = decision_tree.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    dt_accuracy_test.append(accuracy)\n",
        "    dt_precision_test.append(precision)\n",
        "    dt_recall_test.append(recall)\n",
        "    dt_f1_test.append(f1)\n",
        "    dt_fbeta_test.append(fbeta)\n",
        "\n",
        "\n",
        "################################# Random forest ################################\n",
        "\n",
        "    y_pred = random_forest.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    rf_accuracy_test.append(accuracy)\n",
        "    rf_precision_test.append(precision)\n",
        "    rf_recall_test.append(recall)\n",
        "    rf_f1_test.append(f1)\n",
        "    rf_fbeta_test.append(fbeta)\n",
        "\n",
        "############################## Linear Regression ###############################\n",
        "\n",
        "    y_pred = linear.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    lr_accuracy_test.append(accuracy)\n",
        "    lr_precision_test.append(precision)\n",
        "    lr_recall_test.append(recall)\n",
        "    lr_f1_test.append(f1)\n",
        "    lr_fbeta_test.append(fbeta)\n",
        "\n",
        "################################# Combination #################################\n",
        "\n",
        "    y_pred = combined.predict(X_pca_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_pca_test, y_pred)\n",
        "    precision = precision_score(y_pca_test, y_pred)\n",
        "    recall = recall_score(y_pca_test, y_pred)\n",
        "    f1 = f1_score(y_pca_test, y_pred)\n",
        "    fbeta = fbeta_score(y_pca_test, y_pred, beta=1.732)\n",
        "\n",
        "    combi_accuracy_test.append(accuracy)\n",
        "    combi_precision_test.append(precision)\n",
        "    combi_recall_test.append(recall)\n",
        "    combi_f1_test.append(f1)\n",
        "    combi_fbeta_test.append(fbeta)\n",
        "\n",
        "################################### printing ###################################\n",
        "print(\"KNN SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_knn)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_knn)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_knn)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_knn)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_knn)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"SVM SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_svm)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_svm)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_svm)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_svm)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_svm)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"SVM POLY SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_svmpoly)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_svmpoly)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_svmpoly)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_svmpoly)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_svmpoly)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"DECISION TREE SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_dt)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_dt)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_dt)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_dt)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_dt)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"RANDOM FOREST SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_rf)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_rf)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_rf)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_rf)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_rf)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"LINEAR REGRESSION SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_lr)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_lr)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_lr)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_lr)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_lr)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"COMBINATION CLASSIFIER SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(mean_accuracy_scores_combi)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(mean_precision_scores_combi)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(mean_recall_scores_combi)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(mean_f1_scores_combi)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(mean_fbeta_scores_combi)))\n",
        "print(\"\")\n",
        "\n",
        "################################################################################\n",
        "################################### printing ###################################\n",
        "print(\"#####################\")\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"#####################\")\n",
        "print(\"KNN SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(knn_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(knn_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(knn_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(knn_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(knn_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"SVM SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(svm_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(svm_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(svm_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(svm_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(svm_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"SVM POLY SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(svmpoly_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(svmpoly_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(svmpoly_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(svmpoly_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(svmpoly_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"DECISION TREE SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(dt_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(dt_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(dt_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(dt_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(dt_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"RANDOM FOREST SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(rf_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(rf_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(rf_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(rf_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(rf_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"LINEAR REGRESSION SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(lr_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(lr_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(lr_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(lr_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(lr_fbeta_test)))\n",
        "print(\"\")\n",
        "\n",
        "print(\"COMBINATION CLASSIFIER SCORES:\")\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(np.mean(combi_accuracy_test)))\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(np.mean(combi_precision_test)))\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(np.mean(combi_recall_test)))\n",
        "print(\"The mean f1 score of the classifier is: {:.2f}\".format(np.mean(combi_f1_test)))\n",
        "print(\"The mean weighted f1 score of the classifier is: {:.2f}\".format(np.mean(combi_fbeta_test)))\n",
        "print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################## learning curve plot #################################\n",
        "mean_train_scores = np.array(mean_train_scores).mean(axis=1)\n",
        "std_train_scores = np.array(std_train_scores).mean(axis=1)\n",
        "mean_test_scores = np.array(mean_test_scores).mean(axis=1)\n",
        "std_test_scores = np.array(std_test_scores).mean(axis=1)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Learning Curve (Weighted F1 score)\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Score\")\n",
        "\n",
        "plt.fill_between(train_sizes, mean_train_scores - std_train_scores,\n",
        "              mean_train_scores + std_train_scores, alpha=0.1,\n",
        "              color=\"r\")\n",
        "plt.fill_between(train_sizes, mean_test_scores - std_test_scores,\n",
        "              mean_test_scores + std_test_scores, alpha=0.1, color=\"g\")\n",
        "plt.plot(train_sizes, mean_train_scores, 'o-', color=\"r\",\n",
        "      label=\"Training score\")\n",
        "plt.plot(train_sizes, mean_test_scores, 'o-', color=\"g\",\n",
        "      label=\"Cross-validation score\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(\"on\")\n",
        "plt.show()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tD0VJdzM_BPd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}