{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK6nCdvW-Cl0"
      },
      "source": [
        "**TM10007 Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op7Lf97ciGbk"
      },
      "source": [
        "## Import dependencies and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXDkHjQ1-fu9",
        "outputId": "4b42bbe7-ad75-4564-e8de-1dbc2894020a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "import stat\n",
        "from os import path\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "## if data.csv is not present download it from github\n",
        "if not os.path.isfile(\"ecg_data.csv\"):\n",
        "    ## clone repo from githun\n",
        "    if not os.path.isdir(\"tm10007_ml\"):\n",
        "        !git clone https://github.com/jveenland/tm10007_ml.git\n",
        "    ## extract zip file\n",
        "    if not os.path.isfile(\"tm10007_ml/ecg/ecg_data.csv\"):\n",
        "        with zipfile.ZipFile('tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('tm10007_ml/ecg')\n",
        "    ## move data file to root folder\n",
        "    shutil.move('tm10007_ml/ecg/ecg_data.csv', 'ecg_data.csv')\n",
        "\n",
        "    ## Delete cloned repo\n",
        "    for root, dirs, files in os.walk(\"./tm10007_ml\"):  \n",
        "        for dir in dirs:\n",
        "            os.chmod(path.join(root, dir), stat.S_IRWXU)\n",
        "        for file in files:\n",
        "            os.chmod(path.join(root, file), stat.S_IRWXU)\n",
        "    shutil.rmtree('./tm10007_ml')\n",
        "\n",
        "data = pd.read_csv('ecg_data.csv', index_col=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect imported data and clean missing data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot number of missing data per features and per patient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# exclude label column\n",
        "values_features = data.drop(['label'], axis=1)\n",
        "\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_features == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_features == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete rows with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "values_data = data.drop(['label'], axis=1)\n",
        "mask = (values_data != 0).all(axis=1)\n",
        "clean_data=data[mask]\n",
        "dirty_data=data[~mask]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot number of missing data per features and per patient after data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# exclude label column\n",
        "values_clean_data = clean_data.drop(['label'], axis=1)\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_clean_data == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_clean_data == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YaBTRyHiGbl"
      },
      "source": [
        "## Split data into test and train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdZl5eC13JmW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = model_selection.train_test_split(clean_data, test_size=0.2)\n",
        "\n",
        "ECG_ABNORMAL = data[data['label'] == 1]\n",
        "ECG_NORMAL = data[data['label'] == 0]\n",
        "\n",
        "x_train_abnormal, x_test_abnormal = model_selection.train_test_split(ECG_ABNORMAL, test_size=0.2)\n",
        "x_train_normal, x_test_normal = model_selection.train_test_split(ECG_NORMAL,test_size = 0.2)\n",
        "\n",
        "train_set = pd.concat([x_train_normal,x_train_abnormal])\n",
        "test_set = pd.concat([x_test_normal,x_test_abnormal])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVPpduuiGbm"
      },
      "source": [
        "## Scale features of train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1FD3PV6iGbm"
      },
      "outputs": [],
      "source": [
        "# scaling the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# fit the scaler on the train set\n",
        "scaler.fit(train_set)\n",
        "# transform both train and test data set with the scaler\n",
        "# rename the column names to the ones from 'data' again\n",
        "train_set_scaled = pd.DataFrame(scaler.transform(train_set))\n",
        "train_set_scaled.columns=data.columns.values\n",
        "test_set_scaled = pd.DataFrame(scaler.transform(test_set))\n",
        "test_set_scaled.columns=data.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SkcO9K1iGbm"
      },
      "source": [
        "## Select best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms-2RQ6RJ08q"
      },
      "outputs": [],
      "source": [
        "# Extract the features and labels\n",
        "y = train_set['label']\n",
        "X = train_set.drop(['label'], axis=1)\n",
        "\n",
        "# Select the k best features using the chi-squared test\n",
        "selector = SelectKBest(chi2, k=33)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Print the indices of the selected features\n",
        "print(f'The k best features are {selector.get_support(indices=True)}')\n",
        "scores = pd.DataFrame(selector.scores_)\n",
        "sorted_scores = scores.sort_values(scores.columns[0],ascending=False)\n",
        "\n",
        "threshold = 3500\n",
        "below_threshold_to_nan = sorted_scores[sorted_scores > threshold]\n",
        "above_threshold = below_threshold_to_nan.dropna()\n",
        "print(above_threshold)\n",
        "number_above_threshold = len(above_threshold)\n",
        "\n",
        "label_1 = train_set_scaled.columns[6750]\n",
        "print(label_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeJXKo7l47wh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "mGIBOvNF46Cr",
        "outputId": "e4088582-3e77-44ac-d10f-b37bac1a87f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "X = train_set_scaled.iloc[:, :-1].values\n",
        "y = train_set_scaled.iloc[:, -1].values\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(x)\n",
        "\n",
        "df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
        "df_pca['Target'] = y\n",
        "\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Target', data=df_pca)\n",
        "plt.show()\n",
        "\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "loadings = pd.DataFrame(pca.components_)\n",
        "max_loading = loadings.max().max()\n",
        "sorted_loadings = loadings.sort_values(loadings.columns[1],ascending=False)\n",
        "print(sorted_loadings)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
