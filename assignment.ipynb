{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK6nCdvW-Cl0"
      },
      "source": [
        "**TM10007 Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op7Lf97ciGbk"
      },
      "source": [
        "## Import dependencies and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aXDkHjQ1-fu9",
        "outputId": "4b42bbe7-ad75-4564-e8de-1dbc2894020a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tm10007_ml'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 83 (delta 13), reused 12 (delta 12), pack-reused 64\u001b[K\n",
            "Unpacking objects: 100% (83/83), 67.93 MiB | 7.18 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "import stat\n",
        "from os import path\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "## if data.csv is not present download it from github\n",
        "if not os.path.isfile(\"ecg_data.csv\"):\n",
        "    ## clone repo from githun\n",
        "    if not os.path.isdir(\"tm10007_ml\"):\n",
        "        !git clone https://github.com/jveenland/tm10007_ml.git\n",
        "    ## extract zip file\n",
        "    if not os.path.isfile(\"tm10007_ml/ecg/ecg_data.csv\"):\n",
        "        with zipfile.ZipFile('tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('tm10007_ml/ecg')\n",
        "    ## move data file to root folder\n",
        "    shutil.move('tm10007_ml/ecg/ecg_data.csv', 'ecg_data.csv')\n",
        "\n",
        "    ## Delete cloned repo\n",
        "    for root, dirs, files in os.walk(\"./tm10007_ml\"):  \n",
        "        for dir in dirs:\n",
        "            os.chmod(path.join(root, dir), stat.S_IRWXU)\n",
        "        for file in files:\n",
        "            os.chmod(path.join(root, file), stat.S_IRWXU)\n",
        "    shutil.rmtree('./tm10007_ml')\n",
        "\n",
        "data = pd.read_csv('ecg_data.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YaBTRyHiGbl"
      },
      "source": [
        "## Split data into test and train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jdZl5eC13JmW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = model_selection.train_test_split(data, test_size=0.2)\n",
        "\n",
        "ECG_ABNORMAL = data[data['label'] == 1]\n",
        "ECG_NORMAL = data[data['label'] == 0]\n",
        "\n",
        "x_train_abnormal, x_test_abnormal = model_selection.train_test_split(ECG_ABNORMAL, test_size=0.2)\n",
        "x_train_normal, x_test_normal = model_selection.train_test_split(ECG_NORMAL,test_size = 0.2)\n",
        "\n",
        "train_set = pd.concat([x_train_normal,x_train_abnormal])\n",
        "test_set = pd.concat([x_test_normal,x_test_abnormal])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVPpduuiGbm"
      },
      "source": [
        "## Scale features of train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c1FD3PV6iGbm"
      },
      "outputs": [],
      "source": [
        "# scaling the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# fit the scaler on the train set\n",
        "scaler.fit(train_set)\n",
        "# transform both train and test data set with the scaler\n",
        "# rename the column names to the ones from 'data' again\n",
        "train_set_scaled = pd.DataFrame(scaler.transform(train_set))\n",
        "train_set_scaled.columns=data.columns.values\n",
        "test_set_scaled = pd.DataFrame(scaler.transform(test_set))\n",
        "test_set_scaled.columns=data.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SkcO9K1iGbm"
      },
      "source": [
        "## Select best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms-2RQ6RJ08q",
        "outputId": "c8a2faac-b024-4ac0-8658-2362f05fc0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The k best features are [1500 3000 4506 4507 4508 4509 4510 4511 4512 4516 4517 5258 5259 5260\n",
            " 5261 6004 6008 6009 6010 6011 6013 6026 6027 6750 6758 6759 6760 6761\n",
            " 6777 7501 7502 7503 7510]\n",
            "                 0\n",
            "4509  1.242805e+04\n",
            "7501  1.154899e+04\n",
            "4511  1.128543e+04\n",
            "5259  1.118106e+04\n",
            "6010  1.102673e+04\n",
            "...            ...\n",
            "2794  4.030357e-08\n",
            "1439  2.879124e-08\n",
            "4212  2.764047e-08\n",
            "328   1.322937e-08\n",
            "3340  9.248157e-11\n",
            "\n",
            "[9000 rows x 1 columns]\n",
            "0    12428.054272\n",
            "dtype: float64\n",
            "3500\n",
            "                 0\n",
            "4509  12428.054272\n",
            "7501  11548.985068\n",
            "4511  11285.432138\n",
            "5259  11181.058051\n",
            "6010  11026.726385\n",
            "5258  10982.392023\n",
            "6009  10337.877964\n",
            "5260   9139.039921\n",
            "1500   7592.774990\n",
            "7503   7268.205928\n",
            "6008   6723.778917\n",
            "6759   6403.374464\n",
            "6011   6061.082563\n",
            "4510   6048.073915\n",
            "3000   6032.624582\n",
            "6760   5981.860557\n",
            "6027   5659.915483\n",
            "4512   5593.532154\n",
            "6761   5486.768342\n",
            "4517   5047.812350\n",
            "7502   4935.845652\n",
            "7510   4891.074532\n",
            "4507   4878.602778\n",
            "6777   4636.235956\n",
            "6004   4347.070820\n",
            "6013   4063.540568\n",
            "4516   3892.943204\n",
            "6758   3761.000519\n",
            "5261   3759.110785\n",
            "4506   3728.918083\n",
            "6026   3701.875770\n",
            "6750   3687.115383\n",
            "4508   3500.159121\n"
          ]
        }
      ],
      "source": [
        "# Extract the features and labels\n",
        "y = train_set['label']\n",
        "X = train_set.drop(['label'], axis=1)\n",
        "\n",
        "# Select the k best features using the chi-squared test\n",
        "selector = SelectKBest(chi2, k=33)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Print the indices of the selected features\n",
        "print(f'The k best features are {selector.get_support(indices=True)}')\n",
        "scores = pd.DataFrame(selector.scores_)\n",
        "# print(f'The scores for each of the k features are {scores}')\n",
        "\n",
        "sorted_scores = scores.sort_values(scores.columns[0],ascending=False)\n",
        "print(sorted_scores)\n",
        "max_score = scores.max()\n",
        "print(max_score)\n",
        "threshold = 3500\n",
        "print(threshold)\n",
        "below_threshold_to_nan = sorted_scores[sorted_scores > threshold]\n",
        "above_threshold = below_threshold_to_nan.dropna()\n",
        "print(above_threshold)\n",
        "number_above_threshold = len(above_threshold)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}