{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK6nCdvW-Cl0"
      },
      "source": [
        "**TM10007 Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op7Lf97ciGbk"
      },
      "source": [
        "## Import dependencies and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXDkHjQ1-fu9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "import stat\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from os import path\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "## if data.csv is not present download it from github\n",
        "if not os.path.isfile(\"ecg_data.csv\"):\n",
        "    ## clone repo from githun\n",
        "    if not os.path.isdir(\"tm10007_ml\"):\n",
        "        !git clone https://github.com/jveenland/tm10007_ml.git\n",
        "    ## extract zip file\n",
        "    if not os.path.isfile(\"tm10007_ml/ecg/ecg_data.csv\"):\n",
        "        with zipfile.ZipFile('tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('tm10007_ml/ecg')\n",
        "    ## move data file to root folder\n",
        "    shutil.move('tm10007_ml/ecg/ecg_data.csv', 'ecg_data.csv')\n",
        "\n",
        "    ## Delete cloned repo\n",
        "    for root, dirs, files in os.walk(\"./tm10007_ml\"):  \n",
        "        for dir in dirs:\n",
        "            os.chmod(path.join(root, dir), stat.S_IRWXU)\n",
        "        for file in files:\n",
        "            os.chmod(path.join(root, file), stat.S_IRWXU)\n",
        "    shutil.rmtree('./tm10007_ml')\n",
        "\n",
        "data = pd.read_csv('ecg_data.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2PngpnwVZp4"
      },
      "source": [
        "## Inspect imported data and clean missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OBlesnNVZp5"
      },
      "source": [
        "### Plot number of missing data per features and per patient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO8GPYyGVZp5"
      },
      "outputs": [],
      "source": [
        "# exclude label column\n",
        "values_features = data.drop(['label'], axis=1)\n",
        "\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_features == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_features == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKn8tj9NVZp5"
      },
      "source": [
        "### Delete rows with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KutNpZ5zVZp5"
      },
      "outputs": [],
      "source": [
        "values_data = data.drop(['label'], axis=1)\n",
        "mask = (values_data != 0).all(axis=1)\n",
        "clean_data=data[mask]\n",
        "dirty_data=data[~mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzvHjxpkVZp6"
      },
      "source": [
        "### Plot number of missing data per features and per patient after data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_q83MieVZp6"
      },
      "outputs": [],
      "source": [
        "# exclude label column\n",
        "values_clean_data = clean_data.drop(['label'], axis=1)\n",
        "# plot the distribution of missing data per feature\n",
        "num_zeros_features = (values_clean_data == 0).sum(axis=0)\n",
        "plt.scatter(range(len(num_zeros_features)),num_zeros_features)\n",
        "plt.title(\"Distribution of number of missing data per feature\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# plot the distribution of missing data per patient\n",
        "num_zeros_patients=(values_clean_data == 0).sum(axis=1)\n",
        "plt.scatter(range(len(num_zeros_patients)),num_zeros_patients)\n",
        "plt.title(\"Distribution of number of missing data per patient\")\n",
        "plt.ylabel('Number of missing data')\n",
        "plt.xlabel('Patient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YaBTRyHiGbl"
      },
      "source": [
        "## Split data into test and train data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_outlier(dataframe):\n",
        "  new_dfs = []\n",
        "  for i in range(9001):\n",
        "        data=dataframe[dataframe.columns[i]]\n",
        "        Q1 = np.percentile(data, 25)\n",
        "        Q3 = np.percentile(data, 75)\n",
        "        IQD = Q3 - Q1\n",
        "        Upper_outlier_boundary = Q3 + (1.5 * IQD)\n",
        "        Lower_outlier_boundary = Q1 - (1.5 * IQD)\n",
        "        clipped_col = pd.DataFrame({dataframe.columns[i]: dataframe[dataframe.columns[i]].clip(Lower_outlier_boundary, Upper_outlier_boundary)})\n",
        "        new_dfs.append(clipped_col)\n",
        "  clean_outlier_data = pd.concat(new_dfs, axis=1)\n",
        "  return clean_outlier_data\n"
      ],
      "metadata": {
        "id": "g25AJrTN-LqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ECG_ABNORMAL = clean_data[clean_data['label'] == 1]\n",
        "ECG_NORMAL = clean_data[clean_data['label'] == 0]\n",
        "\n",
        "x_train_abnormal, x_test_abnormal = model_selection.train_test_split(ECG_ABNORMAL, test_size=0.2, random_state=30)\n",
        "x_train_normal, x_test_normal = model_selection.train_test_split(ECG_NORMAL,test_size = 0.2,random_state=30)\n",
        "\n",
        "train_set = pd.concat([x_train_normal,x_train_abnormal])\n",
        "test_set_new = pd.concat([x_test_normal,x_test_abnormal])\n",
        "\n",
        "ECG_TRAIN_ABNORMAL = train_set[train_set['label'] == 1]\n",
        "ECG_TRAIN_NORMAL = train_set[train_set['label'] == 0]\n",
        "\n",
        "ECG_TRAIN_DOWNSAMPLED = resample(ECG_TRAIN_NORMAL,\n",
        "                                      replace=False,\n",
        "                                      n_samples=len(ECG_TRAIN_ABNORMAL),\n",
        "                                      random_state=30)\n",
        "\n",
        "# Concat normal and abnormal\n",
        "train_set_downsampled = pd.concat([ECG_TRAIN_ABNORMAL, ECG_TRAIN_DOWNSAMPLED])\n",
        "\n",
        "# Shuffle\n",
        "train_set_shuffled = train_set_downsampled.sample(frac=1, random_state=30)\n",
        "\n",
        "# clean outliers from datasets\n",
        "train_set = clean_outlier(train_set_shuffled)\n",
        "test_set = clean_outlier(test_set_new)\n"
      ],
      "metadata": {
        "id": "MIZxSA52Bgv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVPpduuiGbm"
      },
      "source": [
        "Scale features of train and test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "# fit the scaler on the train set\n",
        "scaler.fit(train_set)\n",
        "\n",
        "# transform both train and test data set with the scaler\n",
        "train_set_scaled = pd.DataFrame(scaler.transform(train_set))\n",
        "train_set_scaled.columns=data.columns.values\n",
        "test_set_scaled = pd.DataFrame(scaler.transform(test_set))\n",
        "test_set_scaled.columns=data.columns.values"
      ],
      "metadata": {
        "id": "jcZpODb4x8mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for normal or not normal distribution of train data"
      ],
      "metadata": {
        "id": "0Q8ZqTiqRvl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import kstest\n",
        "# Statistical tests for normality\n",
        "ks_counter_normal = 0\n",
        "ks_counter_not_normal = 0\n",
        "p_values = []\n",
        "\n",
        "for col in train_set.columns:\n",
        "    # Kolmogorov-Smirnov test\n",
        "    p_value_ks = kstest(train_set[col], 'norm')[1]\n",
        "    p_values.append(p_value_ks)\n",
        "    if p_value_ks > 0.05:\n",
        "        print(f\"{col} is normally distributed (Kolmogorov-Smirnov test p-value = {p_value_ks})\")\n",
        "        ks_counter_normal += 1\n",
        "    else:\n",
        "      ks_counter_not_normal += 1\n",
        "\n",
        "print(f\"The Kolmogorov-Smirnov test gave {ks_counter_normal} normally distributed frequencies & {ks_counter_not_normal} not normally distributed frequencies\")\n"
      ],
      "metadata": {
        "id": "TAhfetuORygJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeJXKo7l47wh"
      },
      "source": [
        "PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGIBOvNF46Cr"
      },
      "outputs": [],
      "source": [
        "x = train_set_scaled.iloc[:, :-1].values\n",
        "y = train_set_scaled.iloc[:, -1].values\n",
        "\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(x)\n",
        "\n",
        "# initialize variables\n",
        "cumulative_variance = 0\n",
        "num_components = 0\n",
        "\n",
        "# loop over each principal component and add its explained variance to the cumulative variance\n",
        "while cumulative_variance < 0.8:\n",
        "    cumulative_variance += pca.explained_variance_ratio_[num_components]\n",
        "    num_components += 1\n",
        "\n",
        "# print the number of components required to reach 80% variance\n",
        "print(\"Number of components to reach 80% variance:\", num_components)\n",
        "\n",
        "pca = PCA(num_components)\n",
        "X_pca = pca.fit_transform(x)\n",
        "\n",
        "# Twee componenten plotten\n",
        "pca_2components = PCA(n_components=2)\n",
        "X_pca_2components = pca_2components.fit_transform(x)\n",
        "df_pca = pd.DataFrame(data=X_pca_2components, columns=['PC1', 'PC2'])\n",
        "df_pca['Target'] = y\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Target', data=df_pca)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colorplot\n",
        "def colorplot(clf, ax, x, y, h=100, precomputer=None):\n",
        "    '''\n",
        "    Overlay the decision areas as colors in an axes.\n",
        "    \n",
        "    Input:\n",
        "        clf: trained classifier\n",
        "        ax: axis to overlay color mesh on\n",
        "        x: feature on x-axis\n",
        "        y: feature on y-axis\n",
        "        h(optional): steps in the mesh\n",
        "    '''\n",
        "    # Create a meshgrid the size of the axis\n",
        "    xstep = (x.max() - x.min() ) / 20.0\n",
        "    ystep = (y.max() - y.min() ) / 20.0\n",
        "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
        "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
        "    h = max((x_max - x_min, y_max - y_min))/h\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    features = np.c_[xx.ravel(), yy.ravel()]\n",
        "    if precomputer is not None:\n",
        "        if type(precomputer) is RBFSampler:\n",
        "            features = precomputer.transform(features)\n",
        "        elif precomputer is rbf_kernel:\n",
        "            features = rbf_kernel(features, X)\n",
        "            \n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    if hasattr(clf, \"decision_function\"):\n",
        "        Z = clf.decision_function(features)\n",
        "    elif hasattr(clf, \"predict_proba\"):\n",
        "        Z = clf.predict_proba(features)\n",
        "    else:\n",
        "        Z = clf.predict(features)\n",
        "        \n",
        "    if len(Z.shape) > 1:\n",
        "        Z = Z[:, 1]\n",
        "    \n",
        "    # Put the result into a color plot\n",
        "    cm = plt.cm.RdBu_r\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm"
      ],
      "metadata": {
        "id": "gQve8qZsMnnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "wLAaeUVWc2Qb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPP6vDwkYSaz"
      },
      "outputs": [],
      "source": [
        "# KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 5, weights='uniform')\n",
        "knn.fit(X_pca,y)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=30)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(knn, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(knn, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(knn, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(knn, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(knn, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(knn, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# # Finding optimal hyperparameters for weighted fbeta_score\n",
        "# params = {'n_neighbors': [3, 5, 7, 9],\n",
        "#           'weights': ['uniform', 'distance']}\n",
        "\n",
        "# grid_search = GridSearchCV(knn, param_grid=params, cv=5, scoring=fbeta_scorer)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "train_sizes, train_scores, test_scores = learning_curve(knn, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM RBF"
      ],
      "metadata": {
        "id": "XPUxS1dOc3-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM RBF\n",
        "svmrbf = SVC(kernel='rbf', gamma=0.1, C=0.1)\n",
        "svmrbf.fit(X_pca,y)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(svmrbf, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(svmrbf, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(svmrbf, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(svmrbf, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(svmrbf, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(svmrbf, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# # Optimize hyperparameters for highest weighted fbeta_score\n",
        "# param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
        "# grid_search = GridSearchCV(estimator=svmrbf, param_grid=param_grid, cv=cv, scoring=fbeta_scorer)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best parameters: \", grid_search.best_params_)\n",
        "train_sizes, train_scores, test_scores = learning_curve(svmrbf, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wynTq7kWq3qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM polynomial"
      ],
      "metadata": {
        "id": "qVhJ5PYrc57O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM polynomial\n",
        "svmpoly = SVC(kernel='poly', degree=1, gamma='scale', C=10)\n",
        "svmpoly.fit(X_pca,y)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(svmpoly, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(svmpoly, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(svmpoly, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(svmpoly, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(svmpoly, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(svmpoly, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# Optimize hyperparameters for highest weighted fbeta_score\n",
        "# param_grid = {'C': [0.1, 1, 10], 'kernel': ['poly'], 'degree': [1, 2, 3, 4], 'gamma': ['scale', 'auto']}\n",
        "# grid_search = GridSearchCV(svmpoly, param_grid=param_grid, scoring=fbeta_scorer, cv=5)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "train_sizes, train_scores, test_scores = learning_curve(svmpoly, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXAoLxdQrfeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "K_HKmg0-c7q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree classifier\n",
        "decision_tree = DecisionTreeClassifier(max_depth= None, min_samples_leaf=16, min_samples_split=2)\n",
        "decision_tree.fit(X_pca,y)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(decision_tree, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(decision_tree, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(decision_tree, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(decision_tree, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(decision_tree, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(decision_tree, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# # Optimizing hyperparameters for highest weighted fbeta_scorer\n",
        "# params = {'max_depth': [None, 5, 10, 15, 20],\n",
        "#           'min_samples_split': [2, 5, 10, 15],\n",
        "#           'min_samples_leaf': [1, 2, 4, 8, 16]}\n",
        "\n",
        "# grid_search = GridSearchCV(decision_tree, param_grid=params, cv=5, scoring=fbeta_scorer)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(decision_tree, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jY9Zx-B1MKR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "3ACoW1XKc9Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest classifier\n",
        "random_forest = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300)\n",
        "random_forest.fit(X_pca,y)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(random_forest, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(random_forest, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(random_forest, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(random_forest, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(random_forest, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(random_forest, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# # Finding hyperparameters for highest weighted fbeta_score\n",
        "# params = {'n_estimators': [100, 200, 300],\n",
        "#           'max_depth': [None, 5, 10],\n",
        "#           'min_samples_split': [2, 5, 10],\n",
        "#           'min_samples_leaf': [1, 2, 4]}\n",
        "\n",
        "# grid_search = GridSearchCV(random_forest, param_grid=params, cv=5, scoring=fbeta_scorer)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "train_sizes, train_scores, test_scores = learning_curve(random_forest, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DV6_52AOMMMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear"
      ],
      "metadata": {
        "id": "iUb_-tw5c--c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear classifier\n",
        "linear = LogisticRegression(C=0.1, penalty='l2', max_iter=1000)\n",
        "linear.fit(X_pca,y)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "binary_accuracy = make_scorer(accuracy_score)\n",
        "accuracy_scores = cross_val_score(linear, X_pca, y, cv=cv, scoring=binary_accuracy)\n",
        "mean_accuracy_score = accuracy_scores.mean()\n",
        "print(\"The mean accuracy score of the classifier is: {:.2f}\".format(mean_accuracy_score))\n",
        "\n",
        "# Compute the precision of the classifier\n",
        "binary_precision = make_scorer(precision_score, average='binary')\n",
        "precision_scores = cross_val_score(linear, X_pca, y, cv=cv, scoring=binary_precision)\n",
        "mean_precision_score = precision_scores.mean()\n",
        "print(\"The mean precision score of the classifier is: {:.2f}\".format(mean_precision_score))\n",
        "\n",
        "# Compute the recall of the classifier\n",
        "binary_recall = make_scorer(recall_score, average='binary')\n",
        "recall_scores = cross_val_score(linear, X_pca, y, cv=cv, scoring=binary_recall)\n",
        "mean_recall_score = recall_scores.mean()\n",
        "print(\"The mean recall score of the classifier is: {:.2f}\".format(mean_recall_score))\n",
        "\n",
        "# Compute the F1 score of the classifier\n",
        "binary_f1 = make_scorer(f1_score, average='binary')\n",
        "f1_scores = cross_val_score(linear, X_pca, y, cv=cv, scoring=binary_f1)\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"The mean F1 score of the classifier is: {:.2f}\".format(mean_f1_score))\n",
        "\n",
        "# Compute the weighted F1 score of the classifier\n",
        "fbeta_scorer = make_scorer(fbeta_score, beta=1.732, average='binary')\n",
        "fbeta_scores = cross_val_score(linear, X_pca, y, cv=cv, scoring=fbeta_scorer)\n",
        "mean_fbeta_score = fbeta_scores.mean()\n",
        "print(\"The mean weighted F1 score of the classifier is: {:.2f}\".format(mean_fbeta_score))\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_estimator(linear, X_pca, y)\n",
        "plt.show()\n",
        "\n",
        "# # Optimizing hyperparameters for highest fbeta_scorer\n",
        "# param_grid = {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "# grid_search = GridSearchCV(linear, param_grid, cv=5, scoring=fbeta_scorer)\n",
        "# grid_search.fit(X_pca, y)\n",
        "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Define the range of training set sizes to use for the learning curve\n",
        "# This specifies that the training set sizes should be 10%, 25%, 50%, 75%, and 100% of the total number of samples\n",
        "# train_sizes = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(linear, X_pca, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), scoring=fbeta_scorer)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3qoYIYBFa_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combination"
      ],
      "metadata": {
        "id": "Nw8DY4kOdAbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the combined classifier\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "estimators = [('random_forest', random_forest), ('svmpoly', svmpoly), ('linear', linear)]\n",
        "\n",
        "combined = VotingClassifier(estimators, voting='hard')\n",
        "\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=30)\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(combined, X_pca, y, cv=cv, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10), scoring='f1_weighted')\n",
        "\n",
        "# Plot the learning curve\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                 color=\"r\")\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "         label=\"Training score\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "         label=\"Cross-validation score\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Weighted F1 score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(\"on\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "6xwu4SR52xe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining 3 classifiers with highest weighted fbeta\n",
        "predicted_labels_random_forest = cross_val_predict(random_forest, X_pca, y, cv=cv)\n",
        "predicted_labels_svmpoly = cross_val_predict(svmpoly, X_pca, y, cv=cv)\n",
        "predicted_labels_linear = cross_val_predict(linear, X_pca, y, cv=cv)\n",
        "voting_predictions = np.array([predicted_labels_svmpoly, predicted_labels_random_forest, predicted_labels_linear])\n",
        "final_classification = np.apply_along_axis(lambda x: np.argmax(np.bincount(x.astype(int))), axis=0, arr=voting_predictions)\n",
        "\n",
        "# final_classification = [max(elem) for elem in zip(predicted_labels_svmrbf, predicted_labels_random_forest, predicted_labels_linear)]\n",
        "\n",
        "y = train_set_scaled.iloc[:, -1].values\n",
        "correct_labels = y.tolist()\n",
        "\n",
        "accuracy = accuracy_score(correct_labels, final_classification)\n",
        "print(f\"The accuracy score is: {accuracy:.2f}\")\n",
        "\n",
        "precision = precision_score(correct_labels,final_classification, average='binary')\n",
        "print(f\"The precision score is: {precision:.2f}\")\n",
        "\n",
        "recall = recall_score(correct_labels, final_classification, average='binary')\n",
        "print(f\"The recall score is: {recall:.2f}\")\n",
        "\n",
        "f1 = f1_score(correct_labels, final_classification, average='binary')\n",
        "print(f\"The f1 score is: {f1:.2f}\")\n",
        "\n",
        "weighted_f1 = fbeta_score(correct_labels, final_classification, beta=1.732, average='binary')\n",
        "print(f\"The weighted f1 score is: {weighted_f1:.2f}\")"
      ],
      "metadata": {
        "id": "VhBppsUb6lDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}